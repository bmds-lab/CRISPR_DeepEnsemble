{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Xiang, X., Corsi, G. I., Anthon, C., Qu, K., Pan, X., Liang, X., Han, P., Dong, Z., Liu, L., Zhong, J., Ma, T., Wang, J., Zhang, X., Jiang, H., Xu, F., Liu, X., Xu, X., Wang, J., Yang, H., Bolund, L., Church, G. M., Lin, L., Gorodkin, J., & Luo, Y. (2021). Enhancing CRISPR-Cas9 gRNA efficiency prediction by data integration and deep learning. Nature Communications, 12(1), 3238.\n",
    "\n",
    "This file was used to preprocess the data obtained from supplementary data 1, pages spCas9_eff_D8-dox and spCas9_eff_D10-dox.\n",
    "\n",
    "NOTE: You will need the optional dependancies to run this file.\\\n",
    "Ensure you have downloaded the human reference genome and built the bowtie2 index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information required to extend sequnces\n",
    "# NOTE: If you get errors about files not exisings, try using absolute paths\n",
    "bowtie2Bin = \"bowtie2\"\n",
    "samtoolsBin = \"samtools\"\n",
    "referenceHumanGenome = \"human.fna\"\n",
    "bowtie2Index = \"human_bt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from Bio.Seq import Seq\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from subprocess import run\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(seq, z='ATCG'):\n",
    "    return [list(map(lambda x: 1 if x==c else 0, z)) for c in seq]\n",
    "assert(encode('ATCG') == [[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc(dna):\n",
    "    try:\n",
    "        complements = str.maketrans('acgtrymkbdhvACGTRYMKBDHV', 'tgcayrkmvhdbTGCAYRKMVHDB')\n",
    "        rcseq = dna.translate(complements)[::-1]\n",
    "        return rcseq\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xiangData_8 = pd.read_excel(\"xiang_2021_d1_spCas9_eff_D8-dox.xlsx\")\n",
    "xiangData_8 = xiangData_8[[\"gRNA\", \"total_indel_eff\"]]\n",
    "xiangData_8.rename({\"gRNA\": \"seq\", \"total_indel_eff\":\"Indel freq\"}, axis=1, inplace=True)\n",
    "xiangData_10 = pd.read_excel(\"xiang_2021_d1_spCas9_eff_D10-dox.xlsx\")\n",
    "xiangData_10 = xiangData_10[[\"gRNA\", \"total_indel_eff\"]]\n",
    "xiangData_10.rename({\"gRNA\": \"seq\", \"total_indel_eff\":\"Indel freq\"}, axis=1, inplace=True)\n",
    "xiangData = pd.merge(xiangData_8, xiangData_10, on=\"seq\", how=\"inner\")\n",
    "xiangData[\"Indel freq\"] = xiangData.mean(axis=1)\n",
    "xiangData = xiangData.drop_duplicates(subset=[\"seq\"])\n",
    "xiangData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", 'w') as outFile :\n",
    "    outFile.writelines([f\"{x}\\n\" for x in xiangData[\"seq\"].to_list()])\n",
    "command = [\n",
    "    bowtie2Bin,\n",
    "    \"-x\",\n",
    "    bowtie2Index,\n",
    "    \"-p\",\n",
    "    \"32\",\n",
    "    \"--reorder\",\n",
    "    \"--no-hd\",\n",
    "    \"-t\",\n",
    "    \"-r\",\n",
    "    \"-U\",\n",
    "    \"input.txt\",\n",
    "    \"-S\",\n",
    "    \"output.txt\"\n",
    "]\n",
    "run(command, check=True)\n",
    "\n",
    "forwarded = 0\n",
    "dropped = 0\n",
    "reversed = []\n",
    "with open(\"output.txt\", \"r\") as inFile, open(\"samtools-faidx-region-file.txt\", \"w\") as outFile:\n",
    "    for line in inFile:\n",
    "        entries = line.split(\"\\t\")\n",
    "        if (\"XM:i:0\" in entries) and (\"XS:i:0\" not in entries):\n",
    "            forwarded += 1\n",
    "            outFile.write(f\"{entries[2]}:{int(entries[3])-4}-{int(entries[3])+26}\\n\")\n",
    "            if (entries[1] == \"16\"):\n",
    "                reversed.append(True)\n",
    "            else:\n",
    "                reversed.append(False)\n",
    "        else:\n",
    "            dropped += 1\n",
    "            length = xiangData.shape[0]\n",
    "            xiangData.drop(xiangData[xiangData[\"seq\"] == entries[9]].index, inplace=True)\n",
    "            if (length == xiangData.shape[0]):\n",
    "                xiangData.drop(xiangData[xiangData[\"seq\"] == rc(entries[9])].index, inplace=True)\n",
    "            if (length == xiangData.shape[0]):\n",
    "                print(f\"Couldn't remove {entries[9]}\")\n",
    "\n",
    "xiangData.insert(0,\"rc\",reversed)\n",
    "\n",
    "command = [\n",
    "    samtoolsBin,\n",
    "    'faidx',\n",
    "    referenceHumanGenome,\n",
    "    '-r',\n",
    "    'samtools-faidx-region-file.txt',\n",
    "    '-o',\n",
    "    'samtools-faidx-region-file-out.txt'\n",
    "]\n",
    "run(command, check=True)\n",
    "\n",
    "with open(\"samtools-faidx-region-file-out.txt\", \"r\") as inFile:\n",
    "    xiangData[\"samtools_raw\"] = [x.strip().upper() for x in inFile.readlines()][1::2]\n",
    "xiangData[\"seq\"] = xiangData.apply(lambda x: rc(x.samtools_raw)[:-1] if  x.rc else x.samtools_raw[:-1], axis=1)\n",
    "xiangData = xiangData[[\"seq\", \"Indel freq\"]]\n",
    "os.unlink(\"input.txt\")\n",
    "os.unlink(\"output.txt\")\n",
    "os.unlink(\"samtools-faidx-region-file.txt\")\n",
    "os.unlink(\"samtools-faidx-region-file-out.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotEncoded = []\n",
    "\n",
    "for seq in xiangData[\"seq\"]:\n",
    "    onehotEncoded.append(np.array(encode(seq)).transpose().tolist())\n",
    "\n",
    "xiangData.insert(1, \"Onehot Encoding\", onehotEncoded)\n",
    "xiangData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meltingTemp = []\n",
    "\n",
    "for seq in xiangData[\"seq\"]:\n",
    "    myseq = Seq(seq)\n",
    "    meltingTemp.append(mt.Tm_NN(myseq))\n",
    "\n",
    "xiangData.insert(2, \"Melting Point\", meltingTemp)\n",
    "xiangData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = []\n",
    "response = []\n",
    "meltingpoint = []\n",
    "\n",
    "for rowIdx, row in xiangData.iterrows():\n",
    "    onehot.append(row[\"Onehot Encoding\"])\n",
    "    response.append(float(row[\"Indel freq\"]))\n",
    "    meltingpoint.append(float(row[\"Melting Point\"]))\n",
    "\n",
    "_onehot = t.tensor(onehot, dtype=t.float32)\n",
    "_response = t.tensor(response, dtype=t.float32)\n",
    "_meltingpoint = t.tensor(meltingpoint, dtype=t.float32)\n",
    "\n",
    "t.save(_onehot, f'xiang_2021_X.pt')\n",
    "t.save(_response, f'xiang_2021_Y.pt')\n",
    "t.save(_meltingpoint, f'xiang_2021_Features.pt')\n",
    "\n",
    "print(_onehot.shape, _response.shape, _meltingpoint.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xiangData.to_csv(\"xiang_2021.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterHub",
   "language": "python",
   "name": "jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
